---
title: "Tarea 1 - CA0307: Estadística Actuarial II"
author:
- Anthony Mauricio Jiménez Navarro | C24067
- Henri Gerard Gabert Hidalgo | B93096
- Juan Pablo Morgan Sandí | C15319
output:
  pdf_document:
    toc: true
  html_document:
    theme: flatly
    toc: true
    toc_float:
      collapsed: true
date: "2024-10-22"
---

# Librerias
```{r}
set.seed(2024)
```

# Ejercicio 1

Primero se crea la función a integrar, la cual sabemos que es
$$
\int_0^1 \frac{e^{-x^2}}{1+x^2} d x
$$

```{r}
f <- function(x) {
  exp(-x^2) / (1 + x^2)
}
```

Una vez hecho lo anterior, programos el algoritmo de Montecarlo.

```{r}
# Método de Montecarlo para aproximar la integral
montecarlo_integration <- function(N) {
  # Generamos N muestras aleatorias entre 0 y 1
  x <- runif(N, 0, 1)
  
  # Evaluamos la función en los puntos muestreados
  fx <- f(x)
  
  # Estimar la integral como el promedio de f(x)
  integral_estimate <- mean(fx)

  return(integral_estimate)
}

N <- 100000  # número de muestras

montecarlo_result <- montecarlo_integration(N)

cat("Aproximación de la integral por Montecarlo:", montecarlo_result, "\n")

```
Ahora, usando integrate.
```{r}
integral_exacta <- integrate(f, 0, 1)
cat("Aproximación de la integral por Integrate:", integral_exacta$value, "\n")
cat("El error absoluto de Integrate:", integral_exacta$abs.error, "\n")
```
Ahora, la diferencia entre el resultado de Montecarlo y el de Integrate es:
```{r}
montecarlo_result - integral_exacta$value
```

# Ejercicio 2

Primero, se crea la función $f_L$, la cual es
$$
f_L(L)= \lambda e^{-\lambda L}
$$
La cual, sabiendo que $\lambda = 1$, es $f_L(L)= e^{-L}$
```{r}
f_L <- function(L) {
  return(exp(-L)) 
}
```

Por el enunciado sabemos también que $g(L) \sim N(3, 4)$
```{r}
g_L <- function(L) {
  return(dnorm(L, mean = 3, sd = 2))
}
```

Una vez creadas las funciones anteriores, se procede a crear el algoritmo de muestreo por importancia.
```{r}
# Establecemos la semilla

n <- 10^4  # número de muestras

# Generar muestras de la distribución normal g
L_samples <- rnorm(n, mean = 3, sd = 2)

# Estimamos el valor esperado usando la importancia ponderada
pesos <- f_L(L_samples) / g_L(L_samples)
perdidas_esperadas <- mean(L_samples * pesos)

cat("La estimación del valor esperado de la pérdida usando muestreo por importancia es:", 
    perdidas_esperadas, "\n")

```

# Ejercicio 3

Se definen los tiempos entre accidentes y las funciones exponencial y gamma, ademas se establecen los parametros de la funcion gamma, todo esto segun lo establecido en el enunciado.
```{r}
tiempos <- c(2.72, 1.93, 1.76, 0.49, 6.12, 0.43, 4.01, 1.71, 2.01, 5.96)

lambda_est <- 1 / mean(tiempos)

# Máximo teórico de la densidad aux (gamma)
m <- max(dgamma(1, 2, 1))

# Simulaciones
U <- runif(10^4)
x <- rgamma(10^4, 2, 1)  # Muestras de la dist aux (gamma)
ngen <- length(x)

# Dist exponecial (objetivo)
dexp1 <- Vectorize(function(x) dexp(x, lambda_est))
```

Algoritmo de aceptacion-rechazo
```{r}
for(i in 1:10^4){
  while((U[i] * m) >= dexp1(x[i])){ 
    U[i] <- runif(1)
    x[i] <- rgamma(1, 2, 1)
    ngen <- ngen + 1
  }
}
```

Resultados
```{r}
cat("Número de generaciones = ", ngen, "\n")
cat("Número medio de aceptados = ", ngen / 10^4, "\n")
cat("Proporción de rechazos = ", 1 - 10^4 / ngen, "\n")

hist(x, breaks = "FD", freq = FALSE, main = "Histograma de \u03BB estimados")
curve(dexp(x, lambda_est), col = 2, lwd = 2, add = TRUE)
```

Intervalo de credibilidad al 99%
```{r}
cred_interval <- quantile(x, probs = c(0.005, 0.995))
cat("Intervalo de credibilidad al 99%: [", cred_interval[1], ", ", cred_interval[2], "]\n")
```
Aceptacion o rechazo de lambda = 5
```{r}
lambda_hip <- 0.5
if(lambda_hip >= cred_interval[1] && lambda_hip <= cred_interval[2]) {
  cat("No se rechaza la hipótesis lambda = 0.5, está dentro del intervalo de credibilidad.\n")
} else {
  cat("Se rechaza la hipótesis lambda = 0.5, está fuera del intervalo de credibilidad.\n")
}
```
# Ejercicio 4

Funcion
$$
f(x) = exp(\frac{sen(10x)}{10cos(x)})
$$
```{r}
f <- function(x) {
  return(exp(sin(10 * x) / (10 * cos(x))))
}
```

Funcion de recalentamiento simulado
```{r}
resim <- function(f, alpha = 0.5, s0 = 5, niter = 1000, mini = 0, maxi = 10) {
  s_n <- s0
  estados <- rep(0, niter)
  iter_count <- 0
  for (k in 1:niter) {
    estados[k] <- s_n
    T <- (1 - alpha)^k  # Enfriamiento
    s_new <- rnorm(1, s_n, 1)
    
    # Asegurarse de que la nueva solución esté dentro de los límites
    if (s_new < mini) { s_new <- mini }
    if (s_new > maxi) { s_new <- maxi }
    
    dif <- f(s_new) - f(s_n)
    if (dif < 0) {
      s_n <- s_new
    } else {
      random <- runif(1, 0, 1)
      if (random < exp(-dif / T)) {
        s_n <- s_new
      }
    }
    iter_count <- iter_count + 1
  }
  return(list(r = s_n, e = estados))
}
```

Aplicacion
```{r}
Resultado <- resim(f, 0.1, 5, 1000, 0, 10)
```

Resultados
```{r}
Resultado$r  # Minimo global
plot(Resultado$e, type = "l", col = "blue", lwd = 2, 
     ylab = "Estados", xlab = "Iteraciones", main = "Estados de la cadena")
```

#Ejercicio 5
A)
```{r}
# Muestra
data <- c(4, 2, 5, 6, 3, 4, 7, 5, 6, 4)
#Numero de iteraciones
n<-10000
#Periodo quemado
L<-1000
#Lambda artibtrario de inicio
lambda_inicio<-runif(1,0,10)

# Función de verosimilitud de Poisson
poisson <- function(lambda, data) {
  prod(dpois(data, lambda))
}

# Función de distribución gamma a priori
gamma_prior <- function(lambda, alpha , beta ) {
  dgamma(lambda, shape = alpha, rate = beta)
}

# Algoritmo de Metropolis-Hastings
metropolis_hastings <- function(data, N = n, lambda_inicial = lambda_inicio, alpha = 3, beta = 2) {
  
  
  Intentos_lambda <- numeric(N)
  Intentos_lambda[1] <- lambda_inicial
  lambda_actual <- lambda_inicial
  Saltos <- 0
  
  for (i in 2:N) {
    propuesta <- rnorm(1, mean = lambda_actual, sd = 0.5)  # Propuesta
    
    if (propuesta > 0) {  # Para evitar valores negativos de lambda, pues es una poisson 
      
      #Usando el factor de bayes, la propuesta/la actual
      Aceptacion <- (poisson(propuesta, data) * gamma_prior(propuesta, alpha, beta)) /
                          (poisson(lambda_actual, data) * gamma_prior(lambda_actual, alpha, beta))
      
      #Criterio de Aceptacion o Rechazo
      if (runif(1) < Aceptacion) {
        lambda_actual <- propuesta
        Saltos <- Saltos + 1
      }
    }
    Intentos_lambda[i] <- lambda_actual
  }
  return(list(Intentos_lambda = Intentos_lambda[(L+1):N], Saltos = Saltos))
}

# Ejecutar el algoritmo con n = 10000
Muestras_MCMC <- metropolis_hastings(data)$Intentos_lambda
```

B)
```{r}
hist(Muestras_MCMC, breaks = 30, prob = TRUE, main = "Histograma de la muestra MCMC",
     xlab = expression(lambda),ylab = "Distribución", col = "blue")
```

C)
```{r}
plot(Muestras_MCMC, type = "l", main = "Traceplot de la muestra MCMC",
     xlab = "Iteraciones", ylab = expression(lambda), col = "blue")
```

D)
```{r}
acf(Muestras_MCMC, main = "Gráfico de Autocorrelación de la muestra MCMC")
```

E)
```{r}
#Normalmente es la suma acumulada/(Iteracion-periodo_quemado)

mean_muestras <- cumsum(Muestras_MCMC) / seq_along(Muestras_MCMC)
plot(mean_muestras, type = "l", main = "Convergencia ergódica de la media de la muestra MCMC",
     xlab = "Iteraciones", ylab = "Promedios acumulados", col = "blue")
```

F)
```{r}
mean_lambda <- mean(Muestras_MCMC)
cat("Estimación de lambda:", mean_lambda, "\n")

cat("Tasa de aceptación \n","NumeroSaltos/TotalIteraciones:" , (metropolis_hastings(data)$Saltos)/(n-L) ,"\n")
```

```{r}

```
